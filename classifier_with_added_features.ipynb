{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook uses preprocessed training data to train different models in order\n",
    "### to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_match_tweets(df):\n",
    "    \"\"\"\n",
    "    Analyze tweets for each match with normalized metrics.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['MatchID', 'Timestamp', 'Tweet', 'EventType']\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with minute-wise analysis including normalized metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # List of key events to track\n",
    "    key_events = ['goal', 'own goal', 'red card', 'yellow card', 'penalty', \n",
    "                 'match start', 'match end', 'half time']\n",
    "    \n",
    "    for match_id, match_data in df.groupby('MatchID'):\n",
    "        # Calculate minute-wise data\n",
    "        start_time = match_data['Timestamp'].min()\n",
    "        match_data['Minute'] = (match_data['Timestamp'] - start_time).dt.total_seconds() // 60\n",
    "        \n",
    "        data_per_minute = match_data.groupby('Minute')\n",
    "        tweet_counts = data_per_minute.size()\n",
    "        \n",
    "        # Calculate event proportions per minute\n",
    "        minute_data = []\n",
    "        for minute, group in data_per_minute:\n",
    "            # Count tweets containing key events\n",
    "            event_tweets = sum(any(f' {event} ' in f' {tweet} ' for event in key_events) \n",
    "                             for tweet in group['Tweet'])\n",
    "            event_proportion = event_tweets / len(group) if len(group) > 0 else 0\n",
    "            \n",
    "            minute_data.append({\n",
    "                'MatchID': float(match_id),\n",
    "                'PeriodID': minute,\n",
    "                'TweetCount': len(group),\n",
    "                'EventProportion': event_proportion\n",
    "            })\n",
    "        \n",
    "        # Convert to DataFrame for easier processing\n",
    "        minute_df = pd.DataFrame(minute_data)\n",
    "        \n",
    "        # Normalize tweet counts and event proportions to [0,1] range\n",
    "        min_tweets = minute_df['TweetCount'].min()\n",
    "        max_tweets = minute_df['TweetCount'].max()\n",
    "        minute_df['tweet_percentage'] = (minute_df['TweetCount'] - min_tweets) / \\\n",
    "                                      (max_tweets - min_tweets) if max_tweets > min_tweets else 0\n",
    "        \n",
    "        min_events = minute_df['EventProportion'].min()\n",
    "        max_events = minute_df['EventProportion'].max()\n",
    "        minute_df['event_percentage'] = (minute_df['EventProportion'] - min_events) / \\\n",
    "                                      (max_events - min_events) if max_events > min_events else 0\n",
    "        \n",
    "        results.append(minute_df)\n",
    "    \n",
    "    # Combine results from all matches\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_tweets.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "final_df = analyze_match_tweets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>TweetCount</th>\n",
       "      <th>EventProportion</th>\n",
       "      <th>tweet_percentage</th>\n",
       "      <th>event_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.150567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.112925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.126476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.203175</td>\n",
       "      <td>0.079048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.054725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>19.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>560</td>\n",
       "      <td>0.019643</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.052778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>19.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>508</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>0.074048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>19.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>465</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.370623</td>\n",
       "      <td>0.109786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>19.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>406</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.320239</td>\n",
       "      <td>0.138976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>340</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.263877</td>\n",
       "      <td>0.134343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID  TweetCount  EventProportion  tweet_percentage  \\\n",
       "0         0.0       0.0          63         0.063492          0.117460   \n",
       "1         0.0       1.0          63         0.047619          0.117460   \n",
       "2         0.0       2.0          75         0.053333          0.155556   \n",
       "3         0.0       3.0          90         0.033333          0.203175   \n",
       "4         0.0       4.0         130         0.023077          0.330159   \n",
       "...       ...       ...         ...              ...               ...   \n",
       "2144     19.0     125.0         560         0.019643          0.451751   \n",
       "2145     19.0     126.0         508         0.027559          0.407344   \n",
       "2146     19.0     127.0         465         0.040860          0.370623   \n",
       "2147     19.0     128.0         406         0.051724          0.320239   \n",
       "2148     19.0     129.0         340         0.050000          0.263877   \n",
       "\n",
       "      event_percentage  \n",
       "0             0.150567  \n",
       "1             0.112925  \n",
       "2             0.126476  \n",
       "3             0.079048  \n",
       "4             0.054725  \n",
       "...                ...  \n",
       "2144          0.052778  \n",
       "2145          0.074048  \n",
       "2146          0.109786  \n",
       "2147          0.138976  \n",
       "2148          0.134343  \n",
       "\n",
       "[2149 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_features = pd.read_csv(\"period_features_glove.csv\") # preprocessing using Glove and dropping certain types of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>ID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>0.214838</td>\n",
       "      <td>0.033723</td>\n",
       "      <td>-0.108459</td>\n",
       "      <td>-0.106916</td>\n",
       "      <td>0.133919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031619</td>\n",
       "      <td>-0.075651</td>\n",
       "      <td>0.031717</td>\n",
       "      <td>0.022333</td>\n",
       "      <td>-0.094636</td>\n",
       "      <td>0.037390</td>\n",
       "      <td>0.245412</td>\n",
       "      <td>0.092223</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>0.137786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114414</td>\n",
       "      <td>0.210811</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>-0.127374</td>\n",
       "      <td>-0.112024</td>\n",
       "      <td>0.133017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024327</td>\n",
       "      <td>-0.037781</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>-0.004945</td>\n",
       "      <td>-0.124407</td>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.114808</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.118851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084405</td>\n",
       "      <td>0.195237</td>\n",
       "      <td>0.064077</td>\n",
       "      <td>-0.152090</td>\n",
       "      <td>-0.065317</td>\n",
       "      <td>0.114473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037781</td>\n",
       "      <td>-0.051512</td>\n",
       "      <td>0.030181</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>-0.131769</td>\n",
       "      <td>0.070388</td>\n",
       "      <td>0.238555</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>-0.009607</td>\n",
       "      <td>0.120924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085226</td>\n",
       "      <td>0.205044</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>-0.124588</td>\n",
       "      <td>-0.083020</td>\n",
       "      <td>0.140426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034552</td>\n",
       "      <td>-0.058735</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>-0.107682</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.242973</td>\n",
       "      <td>0.096682</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>0.116347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094227</td>\n",
       "      <td>0.212355</td>\n",
       "      <td>-0.029741</td>\n",
       "      <td>-0.111316</td>\n",
       "      <td>-0.118624</td>\n",
       "      <td>0.135703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045568</td>\n",
       "      <td>-0.054026</td>\n",
       "      <td>0.025960</td>\n",
       "      <td>0.033239</td>\n",
       "      <td>-0.139287</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>-0.038934</td>\n",
       "      <td>0.158211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>19.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>19_125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>0.273417</td>\n",
       "      <td>-0.008235</td>\n",
       "      <td>-0.195834</td>\n",
       "      <td>0.082377</td>\n",
       "      <td>0.101006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046492</td>\n",
       "      <td>-0.037399</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>-0.019155</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.226146</td>\n",
       "      <td>0.096884</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.164308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>19.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>19_126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.011890</td>\n",
       "      <td>0.258186</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>-0.179704</td>\n",
       "      <td>0.079112</td>\n",
       "      <td>0.107770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047332</td>\n",
       "      <td>-0.041637</td>\n",
       "      <td>0.026681</td>\n",
       "      <td>-0.011228</td>\n",
       "      <td>0.020459</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.219020</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>0.012994</td>\n",
       "      <td>0.163897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>19.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>19_127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.270321</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>-0.183066</td>\n",
       "      <td>0.076836</td>\n",
       "      <td>0.099952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041568</td>\n",
       "      <td>-0.040465</td>\n",
       "      <td>0.031711</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.228404</td>\n",
       "      <td>0.101799</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.158170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>19.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>19_128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.271453</td>\n",
       "      <td>-0.014517</td>\n",
       "      <td>-0.195398</td>\n",
       "      <td>0.070879</td>\n",
       "      <td>0.104112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053858</td>\n",
       "      <td>-0.048433</td>\n",
       "      <td>0.041437</td>\n",
       "      <td>-0.021536</td>\n",
       "      <td>0.023279</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.220829</td>\n",
       "      <td>0.103918</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.162534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>19_129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.274112</td>\n",
       "      <td>-0.008441</td>\n",
       "      <td>-0.171118</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>0.097860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050404</td>\n",
       "      <td>-0.034263</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.234212</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>0.159464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows Ã— 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID      ID  EventType         0         1         2  \\\n",
       "0         0.0       0.0     0_0        0.0  0.091802  0.214838  0.033723   \n",
       "1         0.0       1.0     0_1        0.0  0.114414  0.210811  0.023566   \n",
       "2         0.0       2.0     0_2        0.0  0.084405  0.195237  0.064077   \n",
       "3         0.0       3.0     0_3        0.0  0.085226  0.205044  0.018470   \n",
       "4         0.0       4.0     0_4        0.0  0.094227  0.212355 -0.029741   \n",
       "...       ...       ...     ...        ...       ...       ...       ...   \n",
       "2132     19.0     125.0  19_125        1.0  0.008027  0.273417 -0.008235   \n",
       "2133     19.0     126.0  19_126        1.0 -0.011890  0.258186 -0.023810   \n",
       "2134     19.0     127.0  19_127        1.0 -0.003920  0.270321 -0.013028   \n",
       "2135     19.0     128.0  19_128        1.0  0.017887  0.271453 -0.014517   \n",
       "2136     19.0     129.0  19_129        1.0  0.018207  0.274112 -0.008441   \n",
       "\n",
       "             3         4         5  ...       190       191       192  \\\n",
       "0    -0.108459 -0.106916  0.133919  ... -0.031619 -0.075651  0.031717   \n",
       "1    -0.127374 -0.112024  0.133017  ... -0.024327 -0.037781  0.024221   \n",
       "2    -0.152090 -0.065317  0.114473  ... -0.037781 -0.051512  0.030181   \n",
       "3    -0.124588 -0.083020  0.140426  ... -0.034552 -0.058735  0.046085   \n",
       "4    -0.111316 -0.118624  0.135703  ... -0.045568 -0.054026  0.025960   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2132 -0.195834  0.082377  0.101006  ... -0.046492 -0.037399  0.013002   \n",
       "2133 -0.179704  0.079112  0.107770  ... -0.047332 -0.041637  0.026681   \n",
       "2134 -0.183066  0.076836  0.099952  ... -0.041568 -0.040465  0.031711   \n",
       "2135 -0.195398  0.070879  0.104112  ... -0.053858 -0.048433  0.041437   \n",
       "2136 -0.171118  0.062459  0.097860  ... -0.050404 -0.034263  0.006999   \n",
       "\n",
       "           193       194       195       196       197       198       199  \n",
       "0     0.022333 -0.094636  0.037390  0.245412  0.092223 -0.007181  0.137786  \n",
       "1    -0.004945 -0.124407  0.053369  0.249249  0.114808  0.011257  0.118851  \n",
       "2     0.024942 -0.131769  0.070388  0.238555  0.086125 -0.009607  0.120924  \n",
       "3     0.009542 -0.107682  0.032268  0.242973  0.096682 -0.000472  0.116347  \n",
       "4     0.033239 -0.139287  0.057312  0.235727  0.131300 -0.038934  0.158211  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2132 -0.019155  0.016608  0.013361  0.226146  0.096884  0.004263  0.164308  \n",
       "2133 -0.011228  0.020459  0.005865  0.219020  0.106579  0.012994  0.163897  \n",
       "2134 -0.012235  0.011195  0.006392  0.228404  0.101799  0.006633  0.158170  \n",
       "2135 -0.021536  0.023279  0.014279  0.220829  0.103918  0.003919  0.162534  \n",
       "2136 -0.004743  0.015680  0.011640  0.234212  0.101104 -0.001887  0.159464  \n",
       "\n",
       "[2137 rows x 204 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "        period_features,\n",
    "        final_df,\n",
    "        on=['MatchID', 'PeriodID'],\n",
    "        how='left'  # Keep all rows from other_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>ID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>TweetCount</th>\n",
       "      <th>EventProportion</th>\n",
       "      <th>tweet_percentage</th>\n",
       "      <th>event_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>0.214838</td>\n",
       "      <td>0.033723</td>\n",
       "      <td>-0.108459</td>\n",
       "      <td>-0.106916</td>\n",
       "      <td>0.133919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094636</td>\n",
       "      <td>0.037390</td>\n",
       "      <td>0.245412</td>\n",
       "      <td>0.092223</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>0.137786</td>\n",
       "      <td>63</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.150567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114414</td>\n",
       "      <td>0.210811</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>-0.127374</td>\n",
       "      <td>-0.112024</td>\n",
       "      <td>0.133017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124407</td>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.114808</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>63</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.112925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084405</td>\n",
       "      <td>0.195237</td>\n",
       "      <td>0.064077</td>\n",
       "      <td>-0.152090</td>\n",
       "      <td>-0.065317</td>\n",
       "      <td>0.114473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131769</td>\n",
       "      <td>0.070388</td>\n",
       "      <td>0.238555</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>-0.009607</td>\n",
       "      <td>0.120924</td>\n",
       "      <td>75</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.126476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085226</td>\n",
       "      <td>0.205044</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>-0.124588</td>\n",
       "      <td>-0.083020</td>\n",
       "      <td>0.140426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107682</td>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.242973</td>\n",
       "      <td>0.096682</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>0.116347</td>\n",
       "      <td>90</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.203175</td>\n",
       "      <td>0.079048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094227</td>\n",
       "      <td>0.212355</td>\n",
       "      <td>-0.029741</td>\n",
       "      <td>-0.111316</td>\n",
       "      <td>-0.118624</td>\n",
       "      <td>0.135703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139287</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>-0.038934</td>\n",
       "      <td>0.158211</td>\n",
       "      <td>130</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.054725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>19.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>19_125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>0.273417</td>\n",
       "      <td>-0.008235</td>\n",
       "      <td>-0.195834</td>\n",
       "      <td>0.082377</td>\n",
       "      <td>0.101006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.226146</td>\n",
       "      <td>0.096884</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.164308</td>\n",
       "      <td>560</td>\n",
       "      <td>0.019643</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.052778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>19.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>19_126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.011890</td>\n",
       "      <td>0.258186</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>-0.179704</td>\n",
       "      <td>0.079112</td>\n",
       "      <td>0.107770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020459</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.219020</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>0.012994</td>\n",
       "      <td>0.163897</td>\n",
       "      <td>508</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>0.074048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>19.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>19_127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.270321</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>-0.183066</td>\n",
       "      <td>0.076836</td>\n",
       "      <td>0.099952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.228404</td>\n",
       "      <td>0.101799</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.158170</td>\n",
       "      <td>465</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.370623</td>\n",
       "      <td>0.109786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>19.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>19_128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.271453</td>\n",
       "      <td>-0.014517</td>\n",
       "      <td>-0.195398</td>\n",
       "      <td>0.070879</td>\n",
       "      <td>0.104112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023279</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.220829</td>\n",
       "      <td>0.103918</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.162534</td>\n",
       "      <td>406</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.320239</td>\n",
       "      <td>0.138976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>19.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>19_129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.274112</td>\n",
       "      <td>-0.008441</td>\n",
       "      <td>-0.171118</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>0.097860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.234212</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>0.159464</td>\n",
       "      <td>340</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.263877</td>\n",
       "      <td>0.134343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MatchID  PeriodID      ID  EventType         0         1         2  \\\n",
       "0         0.0       0.0     0_0        0.0  0.091802  0.214838  0.033723   \n",
       "1         0.0       1.0     0_1        0.0  0.114414  0.210811  0.023566   \n",
       "2         0.0       2.0     0_2        0.0  0.084405  0.195237  0.064077   \n",
       "3         0.0       3.0     0_3        0.0  0.085226  0.205044  0.018470   \n",
       "4         0.0       4.0     0_4        0.0  0.094227  0.212355 -0.029741   \n",
       "...       ...       ...     ...        ...       ...       ...       ...   \n",
       "2132     19.0     125.0  19_125        1.0  0.008027  0.273417 -0.008235   \n",
       "2133     19.0     126.0  19_126        1.0 -0.011890  0.258186 -0.023810   \n",
       "2134     19.0     127.0  19_127        1.0 -0.003920  0.270321 -0.013028   \n",
       "2135     19.0     128.0  19_128        1.0  0.017887  0.271453 -0.014517   \n",
       "2136     19.0     129.0  19_129        1.0  0.018207  0.274112 -0.008441   \n",
       "\n",
       "             3         4         5  ...       194       195       196  \\\n",
       "0    -0.108459 -0.106916  0.133919  ... -0.094636  0.037390  0.245412   \n",
       "1    -0.127374 -0.112024  0.133017  ... -0.124407  0.053369  0.249249   \n",
       "2    -0.152090 -0.065317  0.114473  ... -0.131769  0.070388  0.238555   \n",
       "3    -0.124588 -0.083020  0.140426  ... -0.107682  0.032268  0.242973   \n",
       "4    -0.111316 -0.118624  0.135703  ... -0.139287  0.057312  0.235727   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2132 -0.195834  0.082377  0.101006  ...  0.016608  0.013361  0.226146   \n",
       "2133 -0.179704  0.079112  0.107770  ...  0.020459  0.005865  0.219020   \n",
       "2134 -0.183066  0.076836  0.099952  ...  0.011195  0.006392  0.228404   \n",
       "2135 -0.195398  0.070879  0.104112  ...  0.023279  0.014279  0.220829   \n",
       "2136 -0.171118  0.062459  0.097860  ...  0.015680  0.011640  0.234212   \n",
       "\n",
       "           197       198       199  TweetCount  EventProportion  \\\n",
       "0     0.092223 -0.007181  0.137786          63         0.063492   \n",
       "1     0.114808  0.011257  0.118851          63         0.047619   \n",
       "2     0.086125 -0.009607  0.120924          75         0.053333   \n",
       "3     0.096682 -0.000472  0.116347          90         0.033333   \n",
       "4     0.131300 -0.038934  0.158211         130         0.023077   \n",
       "...        ...       ...       ...         ...              ...   \n",
       "2132  0.096884  0.004263  0.164308         560         0.019643   \n",
       "2133  0.106579  0.012994  0.163897         508         0.027559   \n",
       "2134  0.101799  0.006633  0.158170         465         0.040860   \n",
       "2135  0.103918  0.003919  0.162534         406         0.051724   \n",
       "2136  0.101104 -0.001887  0.159464         340         0.050000   \n",
       "\n",
       "      tweet_percentage  event_percentage  \n",
       "0             0.117460          0.150567  \n",
       "1             0.117460          0.112925  \n",
       "2             0.155556          0.126476  \n",
       "3             0.203175          0.079048  \n",
       "4             0.330159          0.054725  \n",
       "...                ...               ...  \n",
       "2132          0.451751          0.052778  \n",
       "2133          0.407344          0.074048  \n",
       "2134          0.370623          0.109786  \n",
       "2135          0.320239          0.138976  \n",
       "2136          0.263877          0.134343  \n",
       "\n",
       "[2137 rows x 208 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the non-numerical features and keep the embeddings values for each period\n",
    "X = merged_df.drop(columns=[\"EventType\", \"MatchID\", \"PeriodID\", \"ID\", \"TweetCount\", \"EventProportion\"]).values\n",
    "# We extract the labels of our training samples\n",
    "y = merged_df[\"EventType\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Evaluating on a test set:\n",
    "\n",
    "# We split our data into a training and test set that we can use to train our classifier without fine-tuning into the\n",
    "# validation set and without submitting too many times into Kaggle\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.7383177570093458\n"
     ]
    }
   ],
   "source": [
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# We set up a basic classifier that we train and then calculate the accuracy on our test set\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000).fit(X, y)\n",
    "# We add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained classifiers\n",
    "preds = clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = preds\n",
    "\n",
    "# Prepare the final prediction dataframes\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"logistic_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.764797507788162\n"
     ]
    }
   ],
   "source": [
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# We set up a basic classifier that we train and then calculate the accuracy on our test set\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100).fit(X, y)\n",
    "\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained classifiers\n",
    "preds = clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = preds\n",
    "\n",
    "# Prepare the final prediction dataframes\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"rf_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (SVM): 0.6931464174454829\n",
      "Cross-validation scores: [0.66889632 0.62876254 0.66555184 0.65886288 0.62541806]\n",
      "Mean CV score: 0.6494983277591974\n",
      "Confusion Matrix:\n",
      "[[181 119]\n",
      " [ 78 264]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.60      0.65       300\n",
      "         1.0       0.69      0.77      0.73       342\n",
      "\n",
      "    accuracy                           0.69       642\n",
      "   macro avg       0.69      0.69      0.69       642\n",
      "weighted avg       0.69      0.69      0.69       642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# Train the SVM classifier on the train set\n",
    "svm_clf = SVC(random_state=42, kernel='rbf', probability=True).fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"Test set accuracy (SVM):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train the SVM classifier on the full dataset\n",
    "svm_clf = SVC(random_state=42, kernel='rbf', probability=True).fit(X, y)\n",
    "\n",
    "# Add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained SVM classifier\n",
    "svm_preds = svm_clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = svm_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"svm_bert_predictions_glove.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (Bagged SVM): 0.6791277258566978\n",
      "Cross-validation scores: [0.6722408  0.6187291  0.65217391 0.63879599 0.61538462]\n",
      "Mean CV score: 0.6394648829431439\n",
      "Confusion Matrix:\n",
      "[[181 119]\n",
      " [ 87 255]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.60      0.64       300\n",
      "         1.0       0.68      0.75      0.71       342\n",
      "\n",
      "    accuracy                           0.68       642\n",
      "   macro avg       0.68      0.67      0.67       642\n",
      "weighted avg       0.68      0.68      0.68       642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load test dataset\n",
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# Create base SVM classifier\n",
    "base_svm = SVC(random_state=42, kernel='rbf', probability=True)\n",
    "\n",
    "# Create bagged SVM classifier\n",
    "bagged_svm = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=70,  # you can adjust this number\n",
    "    max_samples=0.8,  # you can adjust this fraction\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the bagged SVM classifier\n",
    "bagged_svm.fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = bagged_svm.predict(X_test)\n",
    "print(\"Test set accuracy (Bagged SVM):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(bagged_svm, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "y_pred = bagged_svm.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train the bagged SVM classifier on the full dataset\n",
    "bagged_svm = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=70,\n",
    "    max_samples=0.8,\n",
    "    random_state=42\n",
    ").fit(X, y)\n",
    "\n",
    "# Add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained bagged SVM classifier\n",
    "svm_preds = bagged_svm.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = svm_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"bagged_svm_rbf_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (XGBoost): 0.7757009345794392\n",
      "Cross-validation scores: [0.74916388 0.71571906 0.74916388 0.74247492 0.7458194 ]\n",
      "Mean CV score: 0.7404682274247492\n",
      "Confusion Matrix:\n",
      "[[226  74]\n",
      " [ 70 272]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.75      0.76       300\n",
      "         1.0       0.79      0.80      0.79       342\n",
      "\n",
      "    accuracy                           0.78       642\n",
      "   macro avg       0.77      0.77      0.77       642\n",
      "weighted avg       0.78      0.78      0.78       642\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 768, got 200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m X_eval \u001b[38;5;241m=\u001b[39m period_features_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatchID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeriodID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Predict using the trained XGBoost classifier\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m xgb_preds \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Add predictions to the dataframe\u001b[39;00m\n\u001b[1;32m     44\u001b[0m period_features_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m xgb_preds\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/xgboost/sklearn.py:1565\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     X: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1562\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1563\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m-> 1565\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[1;32m   1573\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/xgboost/sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/xgboost/core.py:2520\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2517\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2518\u001b[0m         )\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 2520\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2521\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2522\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2523\u001b[0m         )\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 768, got 200"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Load test dataset\n",
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# Train the XGBoost classifier on the train set\n",
    "xgb_clf = XGBClassifier(\n",
    "    random_state=42,\n",
    "    learning_rate=0.05,  # Reduced\n",
    "    n_estimators=200,    # Increased\n",
    "    max_depth=3,         # Reduced to prevent overfitting\n",
    "    min_child_weight=3,  # Helps with overfitting\n",
    "    subsample=0.8,       # Use 80% of data per tree\n",
    "    colsample_bytree=0.8 # Use 80% of features per tree\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "print(\"Test set accuracy (XGBoost):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(xgb_clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained XGBoost classifier\n",
    "xgb_preds = xgb_clf.predict(X_eval).astype(float)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = xgb_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"xgboost_predictions.csv\", index=False)\n",
    "\n",
    "# Optional: Print feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': range(X.shape[1]),\n",
    "    'importance': xgb_clf.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
