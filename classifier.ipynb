{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook uses preprocessed training data to train different models in order\n",
    "### to compare their performance.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_features = pd.read_csv(\"period_features_glove.csv\") # preprocessing using Glove and dropping certain types of tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the non-numerical features and keep the embeddings values for each period\n",
    "X = period_features.drop(columns=[\"EventType\", \"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "# We extract the labels of our training samples\n",
    "y = period_features[\"EventType\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Evaluating on a test set:\n",
    "\n",
    "# We split our data into a training and test set that we can use to train our classifier without fine-tuning into the\n",
    "# validation set and without submitting too many times into Kaggle\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# We set up a basic classifier that we train and then calculate the accuracy on our test set\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000).fit(X, y)\n",
    "# We add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained classifiers\n",
    "preds = clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = preds\n",
    "\n",
    "# Prepare the final prediction dataframes\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"logistic_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.764797507788162\n"
     ]
    }
   ],
   "source": [
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# We set up a basic classifier that we train and then calculate the accuracy on our test set\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100).fit(X, y)\n",
    "\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained classifiers\n",
    "preds = clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = preds\n",
    "\n",
    "# Prepare the final prediction dataframes\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"rf_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (SVM): 0.7289719626168224\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# Train the SVM classifier on the train set\n",
    "svm_clf = SVC(random_state=42, kernel='linear', probability=True).fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"Test set accuracy (SVM):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Train the SVM classifier on the full dataset\n",
    "svm_clf = SVC(random_state=42, kernel='linear', probability=True).fit(X, y)\n",
    "\n",
    "# Add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained SVM classifier\n",
    "svm_preds = svm_clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = svm_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"svm_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
