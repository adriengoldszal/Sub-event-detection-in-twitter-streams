{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook uses preprocessed training data to train different models in order\n",
    "### to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_features = pd.read_csv('match_analysis_preprocessed_tweets.csv') # preprocessing using Glove and dropping certain types of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>MinuteRenormalized</th>\n",
       "      <th>TweetCountPercentage</th>\n",
       "      <th>EventProportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.063492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.203175</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>19_125.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968992</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.019643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>19_126.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>0.027559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>19_127.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984496</td>\n",
       "      <td>0.370623</td>\n",
       "      <td>0.040860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>19_128.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992248</td>\n",
       "      <td>0.320239</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>19_129.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263877</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  MatchID  EventType  MinuteRenormalized  TweetCountPercentage  \\\n",
       "0        0_0.0        0          0            0.000000              0.117460   \n",
       "1        0_1.0        0          0            0.007752              0.117460   \n",
       "2        0_2.0        0          0            0.015504              0.155556   \n",
       "3        0_3.0        0          0            0.023256              0.203175   \n",
       "4        0_4.0        0          0            0.031008              0.330159   \n",
       "...        ...      ...        ...                 ...                   ...   \n",
       "2144  19_125.0       19          1            0.968992              0.451751   \n",
       "2145  19_126.0       19          1            0.976744              0.407344   \n",
       "2146  19_127.0       19          1            0.984496              0.370623   \n",
       "2147  19_128.0       19          1            0.992248              0.320239   \n",
       "2148  19_129.0       19          1            1.000000              0.263877   \n",
       "\n",
       "      EventProportion  \n",
       "0            0.063492  \n",
       "1            0.047619  \n",
       "2            0.053333  \n",
       "3            0.033333  \n",
       "4            0.023077  \n",
       "...               ...  \n",
       "2144         0.019643  \n",
       "2145         0.027559  \n",
       "2146         0.040860  \n",
       "2147         0.051724  \n",
       "2148         0.050000  \n",
       "\n",
       "[2149 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the non-numerical features and keep the embeddings values for each period\n",
    "X = period_features.drop(columns=[\"MatchID\",\"ID\", \"EventType\"]).values\n",
    "# We extract the labels of our training samples\n",
    "y = period_features[\"EventType\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Evaluating on a test set:\n",
    "\n",
    "# We split our data into a training and test set that we can use to train our classifier without fine-tuning into the\n",
    "# validation set and without submitting too many times into Kaggle\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_features_test = pd.read_csv(\"match_analysis_eval_cleaned_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>MinuteRenormalized</th>\n",
       "      <th>TweetCountPercentage</th>\n",
       "      <th>EventProportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143348</td>\n",
       "      <td>0.037356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.152790</td>\n",
       "      <td>0.051351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.150215</td>\n",
       "      <td>0.041209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.194421</td>\n",
       "      <td>0.042827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16_125.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968992</td>\n",
       "      <td>0.328482</td>\n",
       "      <td>0.057357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>16_126.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.057743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>16_127.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.984496</td>\n",
       "      <td>0.287942</td>\n",
       "      <td>0.038674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>16_128.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.992248</td>\n",
       "      <td>0.252599</td>\n",
       "      <td>0.030488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>16_129.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212058</td>\n",
       "      <td>0.044983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  MatchID  MinuteRenormalized  TweetCountPercentage  \\\n",
       "0       6_0.0        6            0.000000              0.143348   \n",
       "1       6_1.0        6            0.007752              0.152790   \n",
       "2       6_2.0        6            0.015504              0.150215   \n",
       "3       6_3.0        6            0.023256              0.194421   \n",
       "4       6_4.0        6            0.031008              0.261803   \n",
       "..        ...      ...                 ...                   ...   \n",
       "513  16_125.0       16            0.968992              0.328482   \n",
       "514  16_126.0       16            0.976744              0.307692   \n",
       "515  16_127.0       16            0.984496              0.287942   \n",
       "516  16_128.0       16            0.992248              0.252599   \n",
       "517  16_129.0       16            1.000000              0.212058   \n",
       "\n",
       "     EventProportion  \n",
       "0           0.037356  \n",
       "1           0.051351  \n",
       "2           0.041209  \n",
       "3           0.042827  \n",
       "4           0.051282  \n",
       "..               ...  \n",
       "513         0.057357  \n",
       "514         0.057743  \n",
       "515         0.038674  \n",
       "516         0.030488  \n",
       "517         0.044983  \n",
       "\n",
       "[518 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.6232558139534884\n"
     ]
    }
   ],
   "source": [
    "# We set up a basic classifier that we train and then calculate the accuracy on our test set\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000).fit(X, y)\n",
    "# We add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained classifiers\n",
    "preds = clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = preds\n",
    "\n",
    "# Prepare the final prediction dataframes\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"logistic_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.6976744186046512\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but RandomForestClassifier is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m X_eval \u001b[38;5;241m=\u001b[39m period_features_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatchID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Predict using the trained classifiers\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Add predictions to the dataframe\u001b[39;00m\n\u001b[1;32m     15\u001b[0m period_features_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 4 features, but RandomForestClassifier is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "# We set up a basic classifier that we train and then calculate the accuracy on our test set\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=100).fit(X, y)\n",
    "\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained classifiers\n",
    "preds = clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = preds\n",
    "\n",
    "# Prepare the final prediction dataframes\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"rf_better_preprocessing_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (SVM): 0.648062015503876\n",
      "Cross-validation scores: [0.62790698 0.6179402  0.6744186  0.6744186  0.59666667]\n",
      "Mean CV score: 0.6382702104097453\n",
      "Confusion Matrix:\n",
      "[[183 125]\n",
      " [102 235]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62       308\n",
      "           1       0.65      0.70      0.67       337\n",
      "\n",
      "    accuracy                           0.65       645\n",
      "   macro avg       0.65      0.65      0.65       645\n",
      "weighted avg       0.65      0.65      0.65       645\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but SVC is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m X_eval \u001b[38;5;241m=\u001b[39m period_features_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatchID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Predict using the trained SVM classifier\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m svm_preds \u001b[38;5;241m=\u001b[39m \u001b[43msvm_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Add predictions to the dataframe\u001b[39;00m\n\u001b[1;32m     35\u001b[0m period_features_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m svm_preds\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/svm/_base.py:813\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 813\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/svm/_base.py:428\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/svm/_base.py:606\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    603\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 606\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    616\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 4 features, but SVC is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "# Train the SVM classifier on the train set\n",
    "svm_clf = SVC(random_state=42, kernel='rbf', probability=True).fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"Test set accuracy (SVM):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train the SVM classifier on the full dataset\n",
    "svm_clf = SVC(random_state=42, kernel='rbf', probability=True).fit(X, y)\n",
    "\n",
    "# Add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\",\"ID\"]).values\n",
    "\n",
    "# Predict using the trained SVM classifier\n",
    "svm_preds = svm_clf.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = svm_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"svm_bert_predictions_glove.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (Bagged SVM): 0.6791277258566978\n",
      "Cross-validation scores: [0.6722408  0.6187291  0.65217391 0.63879599 0.61538462]\n",
      "Mean CV score: 0.6394648829431439\n",
      "Confusion Matrix:\n",
      "[[181 119]\n",
      " [ 87 255]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.60      0.64       300\n",
      "         1.0       0.68      0.75      0.71       342\n",
      "\n",
      "    accuracy                           0.68       642\n",
      "   macro avg       0.68      0.67      0.67       642\n",
      "weighted avg       0.68      0.68      0.68       642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create base SVM classifier\n",
    "base_svm = SVC(random_state=42, kernel='rbf', probability=True)\n",
    "\n",
    "# Create bagged SVM classifier\n",
    "bagged_svm = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=70,  # you can adjust this number\n",
    "    max_samples=0.8,  # you can adjust this fraction\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the bagged SVM classifier\n",
    "bagged_svm.fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = bagged_svm.predict(X_test)\n",
    "print(\"Test set accuracy (Bagged SVM):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(bagged_svm, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "y_pred = bagged_svm.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train the bagged SVM classifier on the full dataset\n",
    "bagged_svm = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=70,\n",
    "    max_samples=0.8,\n",
    "    random_state=42\n",
    ").fit(X, y)\n",
    "\n",
    "# Add a dummy classifier for sanity purposes\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained bagged SVM classifier\n",
    "svm_preds = bagged_svm.predict(X_eval)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = svm_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"bagged_svm_rbf_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (XGBoost): 0.7757009345794392\n",
      "Cross-validation scores: [0.74916388 0.71571906 0.74916388 0.74247492 0.7458194 ]\n",
      "Mean CV score: 0.7404682274247492\n",
      "Confusion Matrix:\n",
      "[[226  74]\n",
      " [ 70 272]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.75      0.76       300\n",
      "         1.0       0.79      0.80      0.79       342\n",
      "\n",
      "    accuracy                           0.78       642\n",
      "   macro avg       0.77      0.77      0.77       642\n",
      "weighted avg       0.78      0.78      0.78       642\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 768, got 200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m X_eval \u001b[38;5;241m=\u001b[39m period_features_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatchID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeriodID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Predict using the trained XGBoost classifier\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m xgb_preds \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Add predictions to the dataframe\u001b[39;00m\n\u001b[1;32m     44\u001b[0m period_features_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m xgb_preds\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/xgboost/sklearn.py:1565\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     X: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1562\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1563\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m-> 1565\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[1;32m   1573\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/xgboost/sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/Data/adrien.goldszal/data_challenge/lib/python3.11/site-packages/xgboost/core.py:2520\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2517\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2518\u001b[0m         )\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 2520\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2521\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2522\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2523\u001b[0m         )\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 768, got 200"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Load test dataset\n",
    "period_features_test = pd.read_csv(\"period_features_test_glove.csv\")\n",
    "\n",
    "# Train the XGBoost classifier on the train set\n",
    "xgb_clf = XGBClassifier(\n",
    "    random_state=42,\n",
    "    learning_rate=0.05,  # Reduced\n",
    "    n_estimators=200,    # Increased\n",
    "    max_depth=3,         # Reduced to prevent overfitting\n",
    "    min_child_weight=3,  # Helps with overfitting\n",
    "    subsample=0.8,       # Use 80% of data per tree\n",
    "    colsample_bytree=0.8 # Use 80% of features per tree\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction and evaluation\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "print(\"Test set accuracy (XGBoost):\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(xgb_clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean CV score:\", scores.mean())\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Prepare the evaluation dataset\n",
    "X_eval = period_features_test.drop(columns=[\"MatchID\", \"PeriodID\", \"ID\"]).values\n",
    "\n",
    "# Predict using the trained XGBoost classifier\n",
    "xgb_preds = xgb_clf.predict(X_eval).astype(float)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "period_features_test[\"EventType\"] = xgb_preds\n",
    "\n",
    "# Prepare the final prediction dataframe\n",
    "predictions = period_features_test[[\"ID\", \"EventType\"]]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df = predictions\n",
    "pred_df.to_csv(\"xgboost_predictions.csv\", index=False)\n",
    "\n",
    "# Optional: Print feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': range(X.shape[1]),\n",
    "    'importance': xgb_clf.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
